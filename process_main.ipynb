{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d94fd53-f9d5-4fe2-bb61-e6c4f800b226",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d92c6fe-e749-4d65-9765-e0cb2cb351f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset dir if not present\n",
    "if 'Datasets' not in os.listdir():\n",
    "    os.mkdir('Datasets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c37be6fd-a22f-4b37-9cec-106aff73ec31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download datasets\n",
    "\n",
    "## Adult Dataset - Train\n",
    "urllib.request.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\", \"./Datasets/AdultDS.csv\");\n",
    "\n",
    "## Adult Dataset - Test\n",
    "urllib.request.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test\", \"./Datasets/AdultDSTest.csv\");\n",
    "\n",
    "## Adult Dataset Column Names\n",
    "urllib.request.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.names\", \"./Datasets/AdultColNames.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e305f20-5c1e-4a58-bafc-d2845555f013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic preprocessing\n",
    "\n",
    "# Load Adult dataset\n",
    "df_adult = pd.read_csv('./Datasets/AdultDS.csv', header=None)\n",
    "df_adult_test = pd.read_csv('./Datasets/AdultDSTest.csv', skiprows=1, header=None)\n",
    "\n",
    "# Load and process col names from Adult\n",
    "df_adult_colnames = open('./Datasets/AdultColNames.csv', 'r').readlines()\n",
    "df_adult_colnames = [c.split(':')[0] for c in df_adult_colnames[96:]] + ['label']\n",
    "\n",
    "# Get a list of the categorical columns\n",
    "df_adult_cat_cols = open('./Datasets/AdultColNames.csv', 'r').readlines()\n",
    "df_adult_cat_cols = [c.split(':')[1][:11] != ' continuous' for c in df_adult_cat_cols[96:]] + [False]\n",
    "df_adult_cat_cols = pd.Series(df_adult_colnames)[df_adult_cat_cols].tolist()\n",
    "\n",
    "# Get a list of the numerical columns\n",
    "df_adult_num_cols = list(set(df_adult_colnames)-set(df_adult_cat_cols+['label']))\n",
    "        \n",
    "# Assign col names to Adult dataset\n",
    "df_adult.columns = df_adult_colnames\n",
    "df_adult_test.columns = df_adult_colnames\n",
    "\n",
    "# Make label equal for train and test\n",
    "df_adult['label'] = df_adult['label'].map({' <=50K': 0, ' >50K': 1})\n",
    "df_adult_test['label'] = df_adult_test['label'].map({' <=50K.': 0, ' >50K.': 1})\n",
    "\n",
    "# Get shape of train since it will be merged with test to OHE\n",
    "train_shape = df_adult.shape\n",
    "\n",
    "# Merge both datasets\n",
    "df_adult_full = pd.concat([df_adult, df_adult_test])\n",
    "\n",
    "# Make OHE\n",
    "df_adult_full = pd.get_dummies(df_adult_full)\n",
    "\n",
    "# Assign to the train and test set\n",
    "df_adult = df_adult_full.iloc[:train_shape[0],:]\n",
    "df_adult_test = df_adult_full.iloc[train_shape[0]:,:]\n",
    "\n",
    "# Delete merged dataset\n",
    "del df_adult_full\n",
    "\n",
    "column_order = list(df_adult.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "11356bea-dfe4-4103-afef-383bd88845b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataset\n",
    "df_adult.to_pickle('adult_train.pkl')\n",
    "df_adult_test.to_pickle('adult_test.pkl')\n",
    "\n",
    "pd.Series(df_adult_num_cols).to_pickle('adult_num_cols.pkl');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683df3e6-ac66-4a61-807b-1345ff8f2b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feefbfb7-3f7c-41a0-8245-48111868f07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base model\n",
    "model_adult = RandomForestClassifier(random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94a36e31-01c9-490d-a226-94a767df8233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9bf1bdd-6cbf-410e-af7c-273cf411a91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make simple grid-search\n",
    "rf_random = RandomizedSearchCV(estimator = model_adult, param_distributions = random_grid, n_iter = 10, cv = 3, verbose=2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed5e85be-d23e-4ac0-a6ac-d8f3acad639f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   2.7s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.7s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=sqrt, min_samples_leaf=2, min_samples_split=10, n_estimators=200; total time=   1.7s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=600; total time=   5.4s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=600; total time=   5.4s\n",
      "[CV] END bootstrap=False, max_depth=90, max_features=sqrt, min_samples_leaf=4, min_samples_split=10, n_estimators=600; total time=   5.2s\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time=   6.0s\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time=   6.8s\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=600; total time=   7.0s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1400; total time=  12.6s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1400; total time=  11.9s\n",
      "[CV] END bootstrap=True, max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=1400; total time=  12.3s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=  11.8s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=  11.8s\n",
      "[CV] END bootstrap=False, max_depth=80, max_features=auto, min_samples_leaf=1, min_samples_split=10, n_estimators=1000; total time=  11.8s\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   5.1s\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   5.0s\n",
      "[CV] END bootstrap=False, max_depth=60, max_features=sqrt, min_samples_leaf=1, min_samples_split=10, n_estimators=400; total time=   5.0s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=  21.1s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=  21.6s\n",
      "[CV] END bootstrap=False, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=2, n_estimators=2000; total time=  21.1s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.5s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.4s\n",
      "[CV] END bootstrap=True, max_depth=10, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time=   1.3s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1200; total time=   9.2s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1200; total time=   9.0s\n",
      "[CV] END bootstrap=True, max_depth=100, max_features=auto, min_samples_leaf=4, min_samples_split=2, n_estimators=1200; total time=   8.8s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=2000; total time=  15.7s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=2000; total time=  14.8s\n",
      "[CV] END bootstrap=True, max_depth=50, max_features=auto, min_samples_leaf=2, min_samples_split=5, n_estimators=2000; total time=  14.8s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=RandomForestClassifier(n_jobs=-1, random_state=42),\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=42, verbose=2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run grid search\n",
    "rf_random.fit(df_adult.drop(columns=['label']), df_adult['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d47e405f-8c57-47ee-9d3a-ce665bace97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the best model\n",
    "model_adult = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "89b90597-ccb2-468a-9a5e-2b2ce7434ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2878719-6dad-44ba-91db-b6e730d80d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_acc_auc(df, label):\n",
    "    # Get list of predicted classes\n",
    "    pred_class = model_adult.predict(df)\n",
    "    # Get list of probabilities\n",
    "    pred_proba = model_adult.predict_proba(df)\n",
    "    # Calc Accuracy\n",
    "    accuracy = accuracy_score(label, pred_class)\n",
    "    # Calc AUC\n",
    "    auc = roc_auc_score(label, pd.DataFrame(pred_proba)[1].tolist())\n",
    "\n",
    "    print(f'Accuracy:{accuracy}\\nACU:{auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4e2a99b-4327-4a4e-bb9c-54e3e68c4f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For train:\n",
      "Accuracy:0.9039341543564386\n",
      "ACU:0.9669074323663392\n"
     ]
    }
   ],
   "source": [
    "# Calculate Accuracy and AUC for train\n",
    "print('For train:')\n",
    "calc_acc_auc(df_adult.drop(columns=['label']), df_adult['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3d1aa95-e050-4bdd-a14a-3858facfc2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For test:\n",
      "Accuracy:0.8641975308641975\n",
      "ACU:0.9160132219522799\n"
     ]
    }
   ],
   "source": [
    "# Calculate Accuracy and AUC for test\n",
    "print('For test:')\n",
    "calc_acc_auc(df_adult_test.drop(columns=['label']), df_adult_test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488dfee5-f882-4600-9cc6-bafead0e7d54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52c0e0e-edb7-44d9-a18a-f8c59192ba7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "import pickle\n",
    "# now you can save it to a file\n",
    "with open('model_test.pkl', 'wb') as f:\n",
    "    pickle.dump(model_adult, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad481711-04fc-4ae8-9f17-ff459b6bbc4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "776640b3-4a9d-4b24-98e2-7af4ca076274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cfnow(factual, feat_types, model, it_max=100, has_ohe=False):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5299ba0-1246-4708-b813-668d5235f1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c95e86-b77c-4660-b0ba-d89c23438684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b77a75c-f4a7-4e64-af89-d7e9d06f9b26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6401e9b1-5d69-4401-8d47-2526f74fb831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c30d1c5-5470-4177-842d-d4a2cc89d9af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fe1ba7-e807-455a-b445-afc2b79d6b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9b6009d4-dbc4-4965-97bd-1ca7fd177ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_factual(factual):\n",
    "    # Factual must be a pandas Series\n",
    "    try:\n",
    "        assert type(factual) == pd.Series\n",
    "    except AssertionError:\n",
    "        raise TypeError(f'Factual must be a Pandas Series. However it is {type(factual)}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7eab213e-6727-4a74-8a8a-771d7c5f8a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_vars(factual, feat_types):\n",
    "    # The number of feat_types must be the same as the number of factual features\n",
    "    try:\n",
    "        missing_var = list(set(factual.index)-set(feat_types.keys()))\n",
    "        extra_var = list(set(feat_types.keys())-set(factual.index))\n",
    "        assert len(missing_var) == 0 and len(extra_var) == 0\n",
    "    except AssertionError:\n",
    "        if len(missing_var) > 0 and len(extra_var) > 0:\n",
    "            raise AssertionError(f\"\\nThe features:\\n {','.join(missing_var)}\\nmust have their type defined in feat_types.\\\n",
    "                                 \\n\\nAnd the features:\\n {','.join(extra_var)}\\nare not defined in the factual point\")\n",
    "        elif len(missing_var) > 0:\n",
    "            raise AssertionError(f\"The features:\\n {','.join(missing_var)}\\nmust have their type defined in feat_types.\")\n",
    "        elif len(extra_var) > 0:\n",
    "            raise AssertionError(f\"The features:\\n {','.join(extra_var)}\\nare not defined in the factual point.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7f78b186-1c30-4fd0-adad-9635f3ea111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_prob_func(factual, model_predict_proba):\n",
    "    # Test model function and get the classification of factual\n",
    "    try:\n",
    "        prob_fact = model_predict_proba(factual.to_frame().T)\n",
    "    except Exception as err:\n",
    "        raise Exception('Error when using the model_predict_proba function.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "be01819b-454a-4263-8970-554e43b9147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_predictor(factual, model_predict_proba):\n",
    "    # Convert the output of prediction function to something that can be treated\n",
    "\n",
    "    # Check how it's the output of multiple\n",
    "    prob_fact_multiple = model_predict_proba(pd.concat([factual.to_frame().T, factual.to_frame().T]))\n",
    "\n",
    "    # mp1 always return the 1 class and [Num] or [Num, Num, Num]\n",
    "    if str(prob_fact).isnumeric():\n",
    "        # Result returns a number directly\n",
    "\n",
    "        if len(np.array(prob_fact_multiple).shape) == 1:\n",
    "            # Single: Num\n",
    "            # Multiple: [Num, Num, Num]\n",
    "            mp1 = lambda x: np.array([model_predict_proba(x)]) if x.shape[0] == 1 else np.array(model_predict_proba(x))\n",
    "        else:\n",
    "            # Single: Num\n",
    "            # Multiple: [[Num], [Num], [Num]]\n",
    "            index_1 = 0\n",
    "            if len(np.array(prob_fact_multiple)[0]) == 2:\n",
    "                index_1 = 1\n",
    "            # This function gives an array containing the class 1 probability\n",
    "            mp1 = lambda x: np.array([model_predict_proba(x)]) if x.shape[0] == 1 else np.array(model_predict_proba(x))[:, index_1]\n",
    "\n",
    "    elif len(np.array(prob_fact).shape) == 1:\n",
    "        if len(np.array(prob_fact_multiple).shape) == 1:\n",
    "            # Single: [Num]\n",
    "            # Multiple [Num, Num, Num]\n",
    "            mp1 = lambda x: np.array(model_predict_proba(x))\n",
    "        else:\n",
    "            # Single: [Num]\n",
    "            # Multiple [[Num], [Num], [Num]]\n",
    "            index_1 = 0\n",
    "            if len(np.array(prob_fact_multiple)[0]) == 2:\n",
    "                index_1 = 1\n",
    "            mp1 = lambda x: np.array(model_predict_proba(x))[:, index_1]\n",
    "    else:\n",
    "        # Single: [[Num]]\n",
    "        # Multiple [[Num], [Num], [Num]]\n",
    "        index_1 = 0\n",
    "        if len(prob_fact[0]) == 2:\n",
    "            index_1 = 1\n",
    "        # This function gives an array containing the class 1 probability\n",
    "        mp1 = lambda x: np.array(model_predict_proba(x))[:, index_1]\n",
    "    \n",
    "    return mp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3da58f93-c343-48a3-b818-857c154a95fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ohe_params(factual, has_ohe):\n",
    "    ohe_list = []\n",
    "    ohe_indexes = []\n",
    "    # if has_ohe:\n",
    "    if has_ohe:\n",
    "        prefix_to_class = defaultdict(list)\n",
    "        for col_idx, col_name in enumerate(factual.index):\n",
    "            col_split = col_name.split('_')\n",
    "            if len(col_split) > 1:\n",
    "                prefix_to_class[col_split[0]].append(col_idx)\n",
    "\n",
    "        ohe_list = [idx_list for _, idx_list in prefix_to_class.items() if len(idx_list) > 1]\n",
    "        ohe_indexes = [item for sublist in ohe_list for item in sublist]\n",
    "    \n",
    "    return ohe_list, ohe_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10838cd-bc50-44f1-ae67-2273d00a0652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a711190c-adcb-442e-bc69-51e3ae8b201c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "2ba9cbc3-2f80-4cc1-981f-fec197bf1196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_model_class(factual, mp1):\n",
    "    # Define the cf try\n",
    "    cf_try = copy.copy(factual).to_numpy()\n",
    "\n",
    "    mp1c = mp1\n",
    "    # Adjust class, it must be binary and lower than 0\n",
    "    if mp1([cf_try])[0] > 0.5:\n",
    "        mp1c = lambda x: 1-mp1(x)\n",
    "        \n",
    "    return mp1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "05397653-b881-4452-8c13-79211f172623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def super_sedc(factual, mp1c, feat_types, it_max, ohe_list, ohe_indexes):\n",
    "    # For Categorical (binary) there's only one change, flipping 0->1 or 1->0\n",
    "    # For Numerical we can increase 50% of input or decrease 50%\n",
    "\n",
    "    # Define the cf try\n",
    "    cf_try = copy.copy(factual).to_numpy()\n",
    "\n",
    "    # Identify the indexes of categorical and numerical variables\n",
    "    indexes_cat = np.where(np.isin(factual.index, [c for c, t in feat_types.items() if t=='cat']))[0]\n",
    "    indexes_num = sorted(list(set([*range(len(factual))])-set(indexes_cat.tolist())))\n",
    "\n",
    "    # Create identity matrixes for each type of variable\n",
    "    arr_changes_cat_bin = np.eye(len(factual))[list(set(indexes_cat)-set(ohe_indexes))]\n",
    "    arr_changes_cat_ohe = np.eye(len(factual))\n",
    "    arr_changes_num = np.eye(len(factual))[indexes_num]\n",
    "\n",
    "    iterations = 1\n",
    "    cf_try_prob = mp1c(factual.to_frame().T)[0]\n",
    "\n",
    "    tabu_list = []\n",
    "\n",
    "    # Repeat until max iterations \n",
    "    while cf_try_prob <= 0.5 and iterations < it_max:\n",
    "        # Changes\n",
    "        # For categorical binary\n",
    "        changes_cat_bin = arr_changes_cat_bin*(1-2*cf_try)\n",
    "        # For categorical ohe\n",
    "        changes_cat_ohe_list = []\n",
    "        for ohe_group in ohe_list:\n",
    "            changes_cat_ohe_list.append(arr_changes_cat_ohe[ohe_group] - (arr_changes_cat_ohe[ohe_group]*cf_try).sum(axis=0))\n",
    "        if len(changes_cat_ohe_list) > 0:\n",
    "            changes_cat_ohe = np.concatenate(changes_cat_ohe_list)\n",
    "        else:\n",
    "            changes_cat_ohe = []\n",
    "        # For numerical up - HERE, NUMBERS WHICH ARE ZERO WILL REMAIN ZERO\n",
    "        changes_num_up = arr_changes_num*0.5*cf_try\n",
    "        # For numerical down - HERE, NUMBERS WHICH ARE ZERO WILL REMAIN ZERO\n",
    "        changes_num_down = -copy.copy(changes_num_up)\n",
    "\n",
    "        # Create changes array\n",
    "        changes = np.concatenate([c for c in [changes_cat_bin, changes_cat_ohe, changes_num_up, changes_num_down] if len(c) > 0])\n",
    "\n",
    "        # Create array with CF candidates\n",
    "        cf_candidates = cf_try + changes\n",
    "\n",
    "        # Calculate probabilities\n",
    "        prob_cf_candidates = mp1c(cf_candidates)\n",
    "\n",
    "        # Identify which index had the best performance towards objective, it will take the first best\n",
    "        best_arg = np.argmax(prob_cf_candidates)\n",
    "\n",
    "        # Update CF try\n",
    "        cf_try = cf_try+changes[best_arg]\n",
    "\n",
    "        # Update the score\n",
    "        cf_try_prob = mp1c([cf_try])[0]\n",
    "        print(cf_try_prob)\n",
    "\n",
    "        # Update number of tries\n",
    "        iterations += 1\n",
    "\n",
    "        # Repeat process\n",
    "    return cf_try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "269efef2-e426-4444-b0b1-90498a7b6f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "def cfnow(factual, feat_types, model_predict_proba, it_max=100, has_ohe=False):\n",
    "    \n",
    "    # Make checks\n",
    "    check_factual(factual)\n",
    "    check_vars(factual, feat_types)\n",
    "    check_prob_func(factual, model_predict_proba)\n",
    "    \n",
    "    # Generate standardized predictor\n",
    "    mp1 = standardize_predictor(factual, model_predict_proba)\n",
    "    \n",
    "    # Correct class\n",
    "    mp1c = adjust_model_class(factual, mp1)\n",
    "    \n",
    "    # Generate OHE parameters if it has OHE variables\n",
    "    ohe_list, ohe_indexes = get_ohe_params(factual, has_ohe)\n",
    "    \n",
    "    # Generate CF using SEDC\n",
    "    cf_try = super_sedc(factual, mp1c, feat_types, it_max, ohe_list, ohe_indexes)\n",
    "    \n",
    "    return cf_try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe09b24-3a27-499a-88c2-a623a598fd67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "22a22603-79ce-4ad7-b748-2b25ca4dc0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "factual = df_adult_test.drop(columns=['label']).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "de51753f-4310-4de6-8759-8e581c257e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider as default all columns as numerical\n",
    "feat_types = {c: 'num' if c in df_adult_num_cols else 'cat' for c in list(df_adult.columns) if c != 'label'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "3dbb63e2-b19a-4b0b-a585-24fcc9cfeb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predict_proba = model_adult.predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d0bc1e3e-d05a-4e5e-b361-d3774c3292e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "it_max = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "85cd9be7-c1d4-4875-8a81-5a8d52af0678",
   "metadata": {},
   "outputs": [],
   "source": [
    "has_ohe = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc894a6-496c-45d7-adb7-6f3793b5ab18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "25baf8c3-434d-45df-af2d-a069720da763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04718898716665681\n",
      "0.09130976330316087\n",
      "0.13694788412964\n",
      "0.19333279217061275\n",
      "0.2550939972087062\n",
      "0.3056915795485748\n",
      "0.3449086705244311\n",
      "0.40143348963177183\n",
      "0.45984244367101296\n",
      "0.5295809273141039\n"
     ]
    }
   ],
   "source": [
    "test1 = cfnow(factual, feat_types, model_predict_proba, it_max=100, has_ohe=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f33ce1b8-1ffa-45f0-9c11-654bb10a691b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04963643097165748\n",
      "0.12506966319978785\n",
      "0.18760668980068188\n",
      "0.24766627214379697\n",
      "0.30129057910658136\n",
      "0.3802682156022782\n",
      "0.4777896000679885\n",
      "0.6545936259831946\n"
     ]
    }
   ],
   "source": [
    "test2 = cfnow(factual, feat_types, model_predict_proba, it_max=100, has_ohe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60824678-95d3-4c9d-b77d-613cadfe96de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4d9089-bd5c-419d-a048-4f46204056a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b87afd1-cfc3-4947-bc14-cadfb0a4c6ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76812a9e-df07-414d-853c-78ab6fc38159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "abc772b2-5646-48a5-a5e5-fa8d01bee39f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "for ohe_group in ohe_list:\n",
    "    print(sum(cf_try[ohe_group]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "id": "0a50e21a-a56d-453a-a0e5-5bd98ac1b9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    25, 226802,      7,      0,      0,     40,      0,      0,\n",
       "            0,      0,      1,      0,      0,      0,      0,      0,\n",
       "            1,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      1,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      1,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            1,      0,      0,      0,      0,      1,      0,      0,\n",
       "            0,      1,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      1,      0,      0])"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy.copy(factual).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "id": "3c1bb59b-68e8-476e-9b87-efbc65e175ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([    37, 226802,     15,      0,      0,     40,      0,      0,\n",
       "            0,      0,      1,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      1,      0,      0,      0,      0,      0,      0,\n",
       "            0,      1,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            1,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      1,      0,      0,      1,      0,      0,\n",
       "            0,      1,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      0,      0,      0,      0,      0,      0,      0,\n",
       "            0,      1,      0,      0])"
      ]
     },
     "execution_count": 658,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cf_try.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6082d5-0db5-4fce-87c1-64f8f0bd5340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7e6a75-6e3b-4d1a-af4f-baf2e2196278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "5d4e3090-4e19-4666-8190-77f041b0d2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prob_fact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f21889c-cde0-44d1-be21-34032171ce32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
